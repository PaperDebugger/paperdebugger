<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Paper Debugger Development Tools" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <link href="https://fonts.googleapis.com/css2?family=Material+Symbols" rel="stylesheet" />
    <link rel="stylesheet" href="/index.css" />
    <title>Paper Debugger Dev Tools</title>
  </head>
  <body class="p-4">
    <div id="anchor" class="max-w-xl mb-4 px-4 border-slate-200 border rounded-lg">
      <div class="toolbar-left p-4">
        <div class="toolbar-item text-xl font-bold mb-4">PaperDebugger Dev Tools</div>
      </div>
    </div>
    <div id="root-devtools"></div>
    <div id="root-paper-debugger"></div>
    <div>
      Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on
      feature-partitioned, distributed data. However, due to privacy restrictions, few public real-world VFL datasets
      exist for algorithm evaluation, and these represent a limited array of feature distributions. Existing benchmarks
      often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a
      subset of feature distributions, leading to inadequate algorithm performance assessment. This paper addresses
      these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature
      correlation - and proposing associated evaluation metrics and dataset splitting methods. Additionally, we
      introduce a real VFL dataset to address the deficit in image-image VFL scenarios. Our comprehensive evaluation of
      cutting-edge VFL algorithms provides valuable insights for future research in the field.
    </div>
    <script type="module" src="index.tsx"></script>
  </body>
</html>
